{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 테스트 데이터셋을 4개로 나눠 각각 query-make하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"../dataset/\")['test']\n",
    "ds1 = ds.select(range(500))\n",
    "ds2 = ds.select(range(500, 1000))\n",
    "ds3 = ds.select(range(1000, 1500))\n",
    "ds4 = ds.select(range(1500, 2137))\n",
    "\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_maker import GPTQueryMaker\n",
    "\n",
    "\n",
    "prompt = \"\"\"당신은 복잡한 범죄 사실들을 마치 일반인이 얘기하듯 자연스러운 문장으로 풀어쓰는 한국어 챗봇입니다.\n",
    "제가 범죄사실을 말하면, 당신은 실제 변호사에게 물어보듯 해당 범죄사실을 자연스러운 문장으로 풀어쓰세요. \n",
    "이때 다음과 같은 규칙들을 반드시 준수해야합니다.\n",
    "1. 당신이 범죄 사실을 풀어쓸 때 담당할 역할을 피의자, 피해자, 혹은 그 주변인물 중 무작위로 정하세요.\n",
    "2. 다음의 범죄 사실에을 법률 전문가가 아닌 일반인이 물어보듯 자연스럽게 다시 풀어쓰세요.\n",
    "3. 이때, 500자 이내로 서술하세요. 그리고 매번 범죄사실이 주어질 때 마다 다른 사람이 질문하듯 감정, 역할, 말투, 법률 지식 수준 등을 바꿔주세요.\n",
    "4. 마지막에는 실제로 당신이 담당한 역할을 맡은 사람(피의자, 피해자, 혹은 그 주변인물)이 변호사에게 해당 범죄의 경우 어떤 법령에 의해서 처벌을 받는지 법률상담을 요청하는 다양한 질문들을 덧붙여주세요. \n",
    "5. 1인칭으로 대답하세요.\n",
    "\n",
    "범죄 사실은 다음과 같습니다:\n",
    "{crime_facts}\"\"\"\n",
    "\n",
    "\n",
    "query_maker = GPTQueryMaker(prompt=prompt)\n",
    "\n",
    "for ds_part in [ds1, ds2, ds3, ds4]:\n",
    "    ds_part_with_query = query_maker.generate_querys_from_datasets(ds_part, new_col_name='query', from_col_name=\"facts\")\n",
    "    ds_part_with_query.save_to_disk(f'./{ds_part}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query-make된 4개의 데이터셋 조각들(`ds1~4`)를 다시 하나로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "     num_rows: 637\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "\n",
    "ds1 = load_from_disk(\"./ds1/\")\n",
    "ds2 = load_from_disk(\"./ds2/\")\n",
    "ds3 = load_from_disk(\"./ds3/\")\n",
    "ds4 = load_from_disk(\"./ds4/\")\n",
    "\n",
    "ds1, ds2, ds3, ds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "    num_rows: 2137\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = concatenate_datasets([ds1, ds2, ds3, ds4])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 데이터셋(test, val, train)에 test_with_query 데이터셋도 추가하고, 다시 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 13317\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2376\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_ds = load_from_disk(\"../dataset/\")\n",
    "whole_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 13317\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2376\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "    test_with_query: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_ds['test_with_query'] = ds\n",
    "whole_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 13317/13317 [00:00<00:00, 471657.32 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2376/2376 [00:00<00:00, 330821.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2137/2137 [00:00<00:00, 315251.39 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2137/2137 [00:00<00:00, 175330.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "whole_ds.save_to_disk(\"../dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 13317\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2376\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "    test_with_query: Dataset({\n",
       "        features: ['id', 'casetype', 'casename', 'statutes', 'facts', 'query'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_from_disk(\"../dataset/\")\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
